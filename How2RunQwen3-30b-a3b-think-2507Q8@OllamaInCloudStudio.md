# How to Run Qwen3-30b-a3b-think-2507Q8@Ollama In CloudStudio

## 0. å…ˆç¡®ä¿ä¸»æœºå·²æŒ‰å®˜æ–¹æ–‡æ¡£å®Œæˆ NVIDIA å®¹å™¨nvidia-container-toolkitè¿è¡Œæ—¶é…ç½®
å‚è€ƒhttps://docs.ollama.com/docker

## 0.1 Install with Apt
### 0.1.1 Configure the repository 
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey \ <BR>
    | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg <BR>
curl -fsSL https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list \ <BR>
    | sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' \ <BR>
    | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list <BR>
sudo apt-get update <BR>

### 0.1.2 Install the NVIDIA Container Toolkit packages
sudo apt-get install -y nvidia-container-toolkit <BR>

## 0.2 Configure Docker to use Nvidia driver
sudo nvidia-ctk runtime configure --runtime=docker <BR>
sudo systemctl restart docker   ### è¿™æ­¥åœ¨CVMçš„dockerç¯å¢ƒä¸‹éå¿…é¡»ï¼Œåªè¦cat /etc/docker/daemon.json æœ‰nvidia-container-runtimeå­—æ ·å°±è¡Œ<BR>

## 1. å®‰è£…å¹¶åœ¨åå°è¿è¡Œollama
docker run -d --name ollama \
  --gpus all \
  -p 11434:11434 \
  -v ollama:/root/.ollama \
  -e OLLAMA_DEBUG=1 \
  -e OLLAMA_NO_MMAP=1 \
  -e OLLAMA_KV_CACHE_TYPE=q8_0 \
  -e OLLAMA_FLASH_ATTENTION=1 \
  -e OLLAMA_GPU_OVERHEAD=1073741824 \
  --restart always \
  ollama/ollama:latest

Tipsï¼š<BR>
1ã€å¯ä»¥ç”¨docker stop ollma å’Œ docker rm ollama æ¥åœæ­¢å’Œåˆ é™¤è¿™ä¸ªollama containerï¼ç„¶ådocker start ollamaé‡å¯<BR>
2ã€å„ä¸ªå‚æ•°çš„è§£é‡Š<BR>
  --cap-add=IPC_LOCK --ulimit memlock=-1:-1 \    ###è¿™å¥åœ¨CVMä¸‹å¤±è´¥ï¼Œå»æ‰å³å¯ï¼Œä½†ä¸çŸ¥å¯¹é”å®šæƒé‡åœ¨å†…å­˜æ˜¯å¦èƒ½æˆåŠŸï¼Ÿï¼Ÿï¼Ÿ<BR>
  -- e OLLAMA_FLASH_ATTENTION=1 \ ###ä¼¼ä¹æœ€æ–°ç‰ˆé»˜è®¤å·²ç”¨Flash Attentionè¿™ç§ç°ä»£LLMæŠ€æœ¯ï¼ˆé€Ÿåº¦X2ï¼›KV æ˜¾å­˜â—2ï¼Ÿï¼‰<BR>
  -e OLLAMA_GPU_OVERHEAD=6442450944 \ é¢„ç•™6Gæ˜¾å­˜å·²ç»å¾ˆç¨³å®šäº†ï¼›ä½†åæ¥å’¨è¯¢AIå‘ç°è¿™ä¸ªOVERHEADä¸ä¼šç”¨æ¥é¢„ç•™ç»™KVï¼Œæ‰€ä»¥Linuxä¸€èˆ¬å…ˆä¸è®¾ï¼ˆé»˜è®¤ 0ï¼‰æˆ–è®¾ 0.5â€“1 GiBå°±å¤Ÿäº†ï¼›åªæœ‰ä½ è¿˜è¦ç»™å…¶å®ƒè¿›ç¨‹ç•™æ˜¾å­˜ï¼Œæˆ–åœ¨ Windows/WDDM ä¸Šè·‘ï¼Œæ‰è€ƒè™‘åˆ° 2 GiB å·¦å³ã€‚GitHub é‡Œä¹Ÿæœ‰ç»´æŠ¤è€…ç”¨ **512 MiBï¼ˆ536,870,912 å­—èŠ‚ï¼‰**ä½œä¸ºç¤ºä¾‹é¢„ç•™å€¼ã€‚â€‹<BR>
  -e OLLAMA_KV_CACHE_TYPE=f16 \  é»˜è®¤KV Cacheçš„æ˜¯f16=fp16ï¼Œå®é™…è®¾ä¸ºq8_0æ›´çœæ˜¾å­˜ä¸”æ€§èƒ½å‡ æ— æŸå¤±<BR>

**3ã€é‡åˆ°ç±»ä¼¼ä¸‹é¢cgroupé—®é¢˜å°±** <BR>
==docker: Error response from daemon: failed to create task for container: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: error during container init: error running prestart hook #0: exit status 1, stdout: , stderr: Auto-detected mode as 'legacy'
nvidia-container-cli: mount error: failed to add device rules: unable to find any existing device filters attached to the cgroup: bpf_prog_query(BPF_CGROUP_DEVICE) failed: operation not permitted: unknown.==<BR>

sudo mkdir -p /etc/nvidia-container-runtime <BR>
sudo nano /etc/nvidia-container-runtime/config.toml <BR>

Add or ensure the following 2 lines are present: <BR>

[nvidia-container-cli] <BR>
no-cgroups = true <BR>
###The key setting is no-cgroups = true, which disables cgroup device rule enforcement and avoids the bpf_prog_query call . <BR>

[nvidia-container-runtime] <BR>
debug = "/tmp/nvidia-container-runtime.log" <BR>

**ç”¨^xï¼ˆæŒ‰CTRL+Xï¼‰é€€å‡ºç¼–è¾‘åå†æ¬¡è¿è¡Œollamaå¯åŠ¨å‘½ä»¤å°±OKäº†** <BR>

## 2. ä¸‹è½½å¹¶è¿è¡Œæ¨¡å‹qwen3:30b-a3b-thinking-2507-q8_0
## 2.1 ä¸‹è½½æ¨¡å‹
**docker exec -it ollama ollama pull qwen3:30b-a3b-thinking-2507-q8_0** <BR>

## 2.2 å°†è‡ªå·±å¸Œæœ›çš„å‚æ•°å†™å…¥ Modelfile ,å¹¶åˆ›å»ºæ¨¡å‹åˆ«åï¼ˆå¦‚æœGPUæ˜¾å­˜å¤Ÿåˆ™Optionalï¼‰
cat <<'EOF' | docker exec -i ollama sh -lc 'cat > /root/Modelfile'
FROM qwen3:30b-a3b-thinking-2507-q8_0

PARAMETER num_ctx 32768         
PARAMETER num_predict 20480    
PARAMETER num_keep -1           
PARAMETER use_mlock 1           
PARAMETER use_mmap 0
EOF

docker exec  ollama cat /root/Modelfile #æ¥æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å†™å…¥æ­£ç¡®

Tipsï¼šå‚æ•°è¯´æ˜å¦‚ä¸‹  <BR>
PARAMETER num_ctx 32768         # 32K ä¸Šä¸‹æ–‡<BR>
PARAMETER num_predict 15360     # æœ€å¤šä¸€æ¬¡æ€§è¾“å‡º \~15Kï¼ŒåŸæ¥è®¾16Kï¼Œåæ¥å‘ç°Cherry Stuidio16Kè¾“å‡ºæˆªæ–­+é¢„ç•™16Kä¸‹æ–‡å†+æœ€åˆçš„Promptä¼šå¯¼è‡´è¶…32Kï¼Œä¼šKV cacheæ¸…ç©ºï¼Œ-5é—®é¢˜ç»§ç»­å°±ä¼šprefillè¶…æ—¶ï¼æ‰€ä»¥æ”¹æˆ15Ké¿å…ä¹‹ï¼›å†åæ¥å¤ªçŸ­ä¹Ÿä¸è¡Œï¼Œ-5è¿™é“é¢˜æœ‰æ—¶ä¼šæ€è€ƒ15-20Kï¼Œæ€è€ƒä¸­æˆªæ–­cherry studioä¸ä¼šæŠŠæ€è€ƒä¸­çš„tokenså˜æˆä¸Šä¸‹æ–‡ä»è€Œåˆè¦é‡æ–°å¼€å§‹åšé¢˜äº†ï¼›**æ‰€ä»¥æŒ‰è¿™ä¸ªè¯´æ³•ï¼ˆKVcacheä¼šæ¸…ç©ºï¼‰åº”è¯¥è®¾ä¸º20Kï¼ˆ32K-12Kä¸Šæ–‡Prefillæœ€å¤§æ•°è§åé¢çš„é˜è¿°ï¼‰ï¼Œè¿™æ ·åœ¨32Kä¸Šä¸‹æ–‡èƒ½è§£å†³çš„èŒƒå›´å†…ï¼Œæœ€å¤§è§£å†³çš„é—®é¢˜è¾“å…¥æ˜¯12Kï¼Œå¹¶å°½å¯èƒ½1æ¬¡åšå¯¹ï¼ˆæœ€é•¿è¾“å‡º20Kï¼Œå¯¹åº”æ¨ç†æ—¶é—´\~30minï¼‰ï¼ï¼ï¼**Prefill çš„è®¡ç®—å¤æ‚åº¦æ˜¯ O(NÂ²)ï¼ˆä¸»è¦æ¥è‡ª Attention çš„ QK^T è®¡ç®—ï¼‰ï¼Œè€Œ Decode æ˜¯ O(N)ï¼ˆæ¯æ¬¡åªç®—ä¸€ä¸ª token å¯¹å…¨éƒ¨å†å²çš„ attentionï¼‰ã€‚å› æ­¤åœ¨ 8â€“12K è¿™ç±»é•¿åº¦æ—¶çœ‹åˆ°çš„ Prefill/Decode æ¯”å€¼å¸¸å¸¸åªæœ‰ \~1â€“3Ã—ï¼›åªæœ‰åœ¨çŸ­ä¸Šä¸‹æ–‡æˆ–å¼ºæ‰¹å¤„ç†æ—¶ï¼ŒPrefill æ‰æ›´å®¹æ˜“è¾¾åˆ° 10Ã— ä»¥ä¸Šæœ€é«˜100xã€‚<BR>
PARAMETER num_keep -1           # å¯èƒ½æ˜¯é»˜è®¤ï¼Œæœ€å¤§é™åº¦ä¿ç•™å†å²åˆ° KVï¼Œä½†ä»ç„¶ä¸è¶…è¿‡ num_ctx ä¸Šä¸‹æ–‡ <BR>
PARAMETER num_keep 0            # ä¸ä¿ç•™å†å²åˆ° KVï¼Œæ—§æ¶ˆæ¯åœ¨ num_ctx å†…é‡ç®— KVï¼›å¦‚æœè®¾æˆ0ï¼Œåˆ™å¦‚æœå†å²æ¶ˆæ¯å¾ˆé•¿æ—¶Prefillå°±æœ‰å¯èƒ½è¶…æ—¶ï¼ˆCherryStudioæ˜¯5minï¼Œåœ¨<å‡ ä½•é¢˜-5ç¬¬ä¸€æ¬¡è¾“å‡º16Kåå†ç»§ç»­æ—¶å°±ä¼šè¶…æ—¶å¤±è´¥å¯¼è‡´å†å²æ¶ˆæ¯>=16Kçš„å¯¹è¯è¿›è¡Œä¸ä¸‹å»ï¼Œå¹¶ä¸”æŒ‚ä½ç³»ç»Ÿä¸€æ®µæ—¶é—´å½±å“å…¶ä»–å¯¹è¯ç›´åˆ°è¿™ä¸ªPrefillç»“æŸå¤§çº¦20minå·¦å³ï¼‰<BR>
PARAMETER use_mlock 1           # é”å®šæƒé‡åœ¨å†…å­˜ï¼Œé¿å… pageout æŠ–åŠ¨ï¼Œ warning: parameter use_mlock is deprecated<BR>
PARAMETER use_mmap 0            # è¿›ä¸€æ­¥ç¦ç”¨ mmapï¼ˆé…åˆä¸Šé¢ OLLAMA_NO_MMAPï¼Œæ¨¡å‹å‚æ•°æ•´åŒ…åŠ è½½å‡å°‘IOæŠ–åŠ¨ï¼‰<BR>
PARAMETER num_gpu 999  	        # Ollamaä¼šå°è¯•æŠŠå°½å¯èƒ½å¤šçš„å±‚æ”¾åˆ° GPU/ num_gpuæ˜¯åŠ è½½åˆ°GPUçš„å±‚æ•°ï¼Œæ¯”ollamaé»˜è®¤çš„é€Ÿåº¦æ›´å¿«ä¸€ç‚¹ä½†å ç”¨VRAMæ›´å¤šæ›´æ¿€è¿›ä¸€ç‚¹ï¼Ÿï¼Ÿï¼Ÿä½†ä¹ŸæŠ¥é”™äº†ï¼Œæ”¾å¼ƒè¯¥å‚æ•°<BR>

**ç”¨åˆšåšå¥½çš„Modelfileåˆ›å»ºå¸¦å‚æ•°çš„æ¨¡å‹åˆ«å**<BR>
docker exec -it ollama ollama create qwen3-30b-a3b-2507-Q8:ctx32k-mlock -f /root/Modelfile

## 2.3 è¿è¡Œæ¨¡å‹
### 2.3.1 äº¤äº’è¿è¡Œï¼ˆCLIï¼‰
**docker exec -it ollama ollama run qwen3-30b-a3b-2507-Q8:ctx32k-mlock --verbose**

Tipsï¼š<BR>
**ç”¨docker logs -f ollama | grep -E 'memory\.|overhead|offload to cuda' çœ‹KVåœ¨GPUå’ŒCPUä¸­å¦‚ä½•åˆ†é…çš„ï¼ˆ22.5Gæ˜¾å­˜çš„A10ï¼‰ï¼š** <BR>
time=2025-10-22T02:17:58.181Z level=DEBUG source=device.go:206 msg="model weights" device=CUDA0 size="18.5 GiB"<BR>
time=2025-10-22T02:17:58.181Z level=DEBUG source=device.go:211 msg="model weights" device=CPU size="11.7 GiB"<BR>
time=2025-10-22T02:17:58.181Z level=DEBUG source=device.go:217 msg="kv cache" device=CUDA0 size="1.9 GiB"<BR>
time=2025-10-22T02:17:58.181Z level=DEBUG source=device.go:222 msg="kv cache" device=CPU size="1.1 GiB"<BR>
time=2025-10-22T02:17:58.181Z level=DEBUG source=device.go:228 msg="compute graph" device=CUDA0 size="190.5 MiB"<BR>
time=2025-10-22T02:17:58.181Z level=DEBUG source=device.go:233 msg="compute graph" device=CPU size="84.0 MiB"<BR>
time=2025-10-22T02:17:58.181Z level=DEBUG source=device.go:238 msg="total memory" size="33.5 GiB"<BR>

```
ä¹‹å‰åœ¨22.5Gæ˜¾å­˜çš„A10å’ŒOllamaç¼ºçœå‚æ•°ä¸‹ï¼Œè¿è¡Œqwen3-30b-a3b-2507-Q8æ¨¡å‹ï¼Œåœ¨é•¿ä¸Šä¸‹æ–‡é—®é¢˜æ—¶ï¼ˆä¾‹å¦‚å‡ ä½•é¢˜-5ï¼Œå›ç­”åœ¨17-42Kæ—¶ï¼‰ä¼šAPI crashï¼ˆæ— ååº”ï¼Œè¦é ç­‰å¾…20minä»¥ä¸Šæˆ–é‡å¯Dockeræ¥æ¢å¤ï¼‰ï¼Œæ‰€ä»¥æˆ‘æ€»ç»“ä¸€ä¸‹æˆ‘çš„éœ€æ±‚ï¼Œè¯·AIç»™å‡ºç›¸å…³çš„docker runå‘½ä»¤ï¼š
1ã€åœ¨24Gæ˜¾å­˜ï¼ˆå®é™…22.5Gï¼‰çš„A10æ˜¾å¡20æ ¸116Gå†…å­˜çš„æœºå™¨ä¸Šè¦è¿è¡Œollamaï¼Œç”¨qwen3-30b-a3b-2507-Q8æ¨¡å‹ï¼Œæ¨¡å‹å¤§å°32GB
2ã€å¸Œæœ›ç•™6Gæ˜¾å­˜ç»™KV Cacheï¼ˆå¯¹åº”KVåœ¨FP16ä¸‹èƒ½é¢„ç•™64Kçš„ä¸Šä¸‹æ–‡ï¼‰
3ã€num_keepè®¾ä¸º0ï¼Œä¿è¯ä»¥å‰çš„å¯¹è¯ä¸ä¿ç•™åœ¨KVï¼Œä¹‹å‰çš„å¯¹è¯åœ¨ä¸‹é¢num_ctxé•¿åº¦å†…ä¼šè¢«é‡æ–°è®¡ç®—KVï¼ˆè¿™ä¸ªä¸ä¿ç•™KVå¯¹å¤šä¸ªå¯¹è¯æ˜¯æœ€å°åŒ–KVçš„ç»“æœï¼‰
4ã€num_ctxè®¾ä¸º32Kï¼Œ32Kä¸Šä¸‹æ–‡çš„å¯¹è¯ï¼Œæœ€å¤§ä¼šäº§ç”Ÿ3Gæ˜¾å­˜éœ€æ±‚ï¼ˆKV cacheç”¨é»˜è®¤fp16çš„æƒ…å†µä¸‹ï¼‰
5ã€num_predictè®¾ä¸º15Kï¼Œä¸€æ¬¡æ€§æœ€å¤§è¾“å‡ºè¾¾åˆ°\~15Kæ—¶ä¼šæˆªæ–­
6ã€ä½¿ç”¨mlockæŠŠæ¨¡å‹æƒé‡æ–‡ä»¶é”å®šåœ¨å†…å­˜ä¸­ï¼Œé¿å…Pageoutï¼ˆåœ¨å†…å­˜æœ‰å‹åŠ›æ—¶ä¾‹å¦‚å†…å­˜å ç”¨è¾¾80-85%æ—¶ï¼‰äº§ç”ŸIOæŠ–åŠ¨é€ æˆAPIçš„crashï¼ˆæ— ååº”ï¼Œè¦é ç­‰å¾…20minä»¥ä¸Šæˆ–é‡å¯Dockeræ¥æ¢å¤ï¼‰
7ã€ç¦ç”¨mmapæ¨¡å‹å‚æ•°æ•´åŒ…åŠ è½½å‡å°‘IOæŠ–åŠ¨ï¼Œé¿å…crash
ä½†æ˜¯æœ€åå‘ç°Crashçš„æ ¸å¿ƒåŸå› æ˜¯ï¼š
1ï¼‰å› ä¸ºæ²¡è®¾ç½®OVERHEADåœ¨å…¶ä»–è€—æ˜¾å­˜æ—¶ï¼ˆéæ¨¡å‹æƒé‡+KV cacheï¼‰çªç„¶çˆ†æ˜¾å­˜å¯¼è‡´Crashï¼ˆå‘ç°è¿‡1æ¬¡ï¼‰ï¼›è¿™ä¸ªä¸»è¦é è®¾ç½®OLLAMA_GPU_OVERHEADæ¥è§£å†³
åŒæ—¶å³ä½¿é¢„ç•™äº†æ˜¾å­˜ç»™KV Cacheï¼Œä¹Ÿä¼šåœ¨å¤šå¯¹è¯ä¸”é•¿ä¸Šä¸‹æ–‡æ—¶è¶…è¿‡åŸæ¥çš„é¢„ç•™ï¼Œè¿™æ ·æ˜¾å­˜ä¼šä¸å¤Ÿï¼Œå°±ä¼šæœ‰æ˜¾å­˜å’Œå†…å­˜é—´ä¼ è¾“ï¼Œå°±æœ‰å¯èƒ½ä¼šå¯¼è‡´crashï¼›è¿™ä¸ªé OLLAMA_KV_CACHE_TYPE=q8_0+è°ƒèŠ‚num_ctx/num_predict/num_gpuæ¥è§£å†³
2ï¼‰æ¨¡å‹å‚æ•°ä¸å¸¸é©»æ˜¾å­˜+å†…å­˜ï¼Œåœ¨å†…å­˜ç´§å¼ æ—¶ï¼ˆ>=85%ï¼‰æˆ–åªè¦æ˜¯é»˜è®¤å¯ç”¨mmapæ—¶å°±æœ‰å¯èƒ½ä¸ç¡¬ç›˜Pageoutæ—¶ä¼šIOæŠ–åŠ¨å°±æœ‰å¯èƒ½ä¼šå¯¼è‡´crashï¼›è¿™ä¸ªä¸»è¦é å†…å­˜è¶³å¤Ÿå¤§å’Œç¦ç”¨mmapæ¥è§£å†³
3ï¼‰æœ€å¤šçš„æƒ…å†µï¼šé¦–å­—èŠ‚çš„Prefillé˜¶æ®µè¿‡é•¿Timeoutåå¯¼è‡´Crashï¼ˆPrefillè¶…5åˆ†é’Ÿåå‘é€ç»™Cherry Studioç«¯ï¼Œä½†Cherry Studioå·²ç»timeoutäº†æ‰€ä»¥ollamaè¿›ç¨‹å°±é”æ­»åœ¨é‚£é‡Œï¼‰ï¼Œé€šè¿‡num_keep=-1ä½¿å¾—å†å²æ¶ˆæ¯çš„KV Cacheæœ€å¤§åŒ–åŠ é€Ÿï¼Œä½†å½“å‰è½®çš„Promptä¸å†å²æ¶ˆæ¯ä¹‹é—´ä¹Ÿè¦è®¡ç®—KVï¼Œæ­¤æ—¶å¦‚æœå†å²æ¶ˆæ¯è¿‡é•¿ä¸”é€Ÿåº¦è¿‡æ…¢å°±å¯èƒ½5minTimeoutï¼Œç›®å‰OLLAMA_KV_CACHE_TYPE=f16æ—¶å®æµ‹8Kå†å²æ¶ˆæ¯+ç»§ç»­OKï¼Œ16Kå†å²æ¶ˆæ¯+199tokens Promptå¡å£³ï¼›è¿™ä¸ªé OLLAMA_KV_CACHE_TYPE=q8_0æé«˜é€Ÿåº¦æ¥è§£å†³ï¼Œå®æµ‹KV=q8_0æ—¶KV cache 1Gåœ¨GPU0.5Gåœ¨CPUï¼Œä¸Šæ–‡æœ€é•¿å¯è¾¾12-13Kæ‰5minTimeout\~aÂ²=ï¼ˆ12kï¼‰Â²KVè®¡ç®—é‡ï¼Œå¦‚æœå§‹ç»ˆåœ¨ä¸€ä¸ªå¯¹è¯é‡Œé KV cacheçš„è¯å³ä½¿è¾¾åˆ°32Kä¸Šä¸‹æ–‡åœ¨è¾“å‡º16Kå+"ç»§ç»­"ä¹ŸOKäº†å› ä¸ºåªæœ‰~2ab=ï¼ˆ16K*2*2ï¼‰è®¡ç®—é‡ï¼ˆå…¶ä¸­a=å†å²æ¶ˆæ¯tokensæ•°ï¼Œb=å½“å‰promptçš„tokensæ•°ï¼‰
```

#### 2.3.2 æˆ–è€…èµ° HTTP APIï¼ˆé»˜è®¤ 11434ï¼‰æ¥æµ‹è¯•
curl http://localhost:11434/api/generate -d '{
  "model": "qwen3-30b-a3b-2507-Q8:ctx32k-mlock",
  "prompt": "hello",
  "stream": false
}'

# 3. æœ€ç»ˆç»“è®ºï¼š
ğŸ”´1ï¼‰åœ¨24GBæ˜¾å­˜20C116Gå†…å­˜çš„A10æœºå™¨ä¸ŠGPUæ˜¾å­˜ä¸è¶³å®¹çº³qwen3-30b-a3b2507Q8ï¼ˆ**å®Œæˆè¯¸å¦‚ç¿»è¯‘/è¾…å¯¼é«˜ä¸­ç”Ÿä½œä¸š/ä¸­çº§ç¨‹åºå‘˜ä¹‹ç±»çš„å·¥ä½œï¼ˆæ™ºåŠ›~GPT4.35æ¥è¿‘DS R1æ»¡è¡€è€ç‰ˆæœ¬ï¼‰ï¼‰çš„32GBæ¨¡å‹éœ€è¦GPU/CPUæ··åˆæ¨ç†çš„æƒ…å†µä¸‹ï¼ŒPrefillæ˜¯ä¸»è¦ç“¶é¢ˆ**ï¼ˆKVè®¾q8_0æ—¶å®æµ‹æ¨ç†ç”Ÿæˆé€Ÿåº¦ä¸º30t/sï¼ŒPrefillé€Ÿåº¦å—æ··åˆæ¨ç†æ‹–ç´¯å®æµ‹40t/sï¼‰<BR>
ğŸ”´2ï¼‰**ä¸šåŠ¡ä¸ŠOllamaåªèƒ½ä¸ºå•äººæœåŠ¡ä¸”åœ¨Ollama CLIä¸Šä½“éªŒè¶…å¥½ï¼Œå®æµ‹è¿‡ä½¿ç”¨2hourä»¥ä¸Šå®Œå…¨æ­£å¸¸ï¼›ä½†ç”¨Cherry Studioå®¢æˆ·ç«¯æ—¶ä½“éªŒå—é™ä½†ä¹Ÿèƒ½å…·å¤‡åœ¨ä¸€å®šä¸Šä¸‹æ–‡æ¡ä»¶ä¸‹**<BR>
å…·ä½“ä½“éªŒå—é™å¦‚ä¸‹ï¼š<BR>
1ï¼‰**åœ¨Cherry Studioä¸­é¦–æ¬¡æœ€å¤§é—®é¢˜è¾“å…¥æ§åˆ¶åœ¨12Kï¼Œä¸Šä¸‹æ–‡å¯ä»¥è¾¾åˆ°32Kæœ€å¤§è¾“å‡º20Kæ—¶ä¿æŒåœ¨ä¸€ä¸ªå¯¹è¯ä¸­**ï¼ˆé˜²æ­¢KV cacheåˆ‡æ¢å¯¹è¯æ—¶clearï¼‰æŒç»­é—®å®Œä½“éªŒç¨³å®šï¼ˆé•¿å¯¹è¯æ—¶ä¿æŒè€å¿ƒä¸”ä¸è¦ä¸­æ–­ï¼Œä¾‹å¦‚å‡ ä½•é¢˜-5å…¨å¯¹ï¼Œå›ç­”ä¸€èˆ¬åœ¨12-20Kéœ€è¦å¤§è‡´15-30minï¼‰ï¼›å½“Prefill 5minè¶…æ—¶æˆ–è¢«ä¸­æ–­æ—¶ç³»ç»Ÿå¯¹åé¢çš„å¯¹è¯æ— ååº”ï¼Œæ­¤æ—¶restart dockeråé‡æ–°åŠ è½½æ¨¡å‹å³å¯<BR>
2ï¼‰åœ¨ollama CLIä¸‹æ²¡æœ‰ä¸Šä¸‹æ–‡çš„é™åˆ¶ï¼ˆå“ªæ€•æ¨¡å‹æ–‡ä»¶ä¸­è®¾äº†num_ctx=32Kï¼‰ä¹Ÿä¸ä¼šPrefill Timeoutï¼ˆä¼¼ä¹KV Cacheä¸€ç›´å¯ä»¥æ‰©å±•åªè¦å†…å­˜å¤Ÿï¼‰ï¼Œå®é™…å¯¹è¯è¶…2hoursï¼Œæˆ‘çš„æµ‹è¯•é¢˜ç›®èµ°äº†è¿‘2éï¼Œä¸€åˆ‡éƒ½è¿˜æ­£å¸¸ï¼Œä½“éªŒéå¸¸å¥½é™¤äº†MDæ ¼å¼æ²¡æœ‰renderå¤–<BR>
3ï¼‰32Gçš„V100 Q8å’ŒQ4å®æµ‹é€Ÿåº¦éƒ½åªæœ‰A10æœºå™¨çš„80%ï¼Œåˆ†åˆ«æ˜¯Q4 80t/sï¼ŒQ8 24t/sï¼ˆè™½ç»å¤§éƒ¨åˆ†éƒ½åœ¨GPUä¸Šäº†ä½†V100æœºå™¨CPUæ˜¯8Cæ¯”A10çš„20Cå¼±ä¸å°‘ï¼‰ï¼Œä¸”æ¯”A10è¿˜è´µï¼Œæ‰€ä»¥ä¸€èˆ¬ä¸ç”¨ï¼<BR>
ğŸ”´4ï¼‰åœ¨22.5Gæ˜¾å­˜çš„A10çš„Ollamaä¸‹è¿è¡Œqwen3-30b-a3b-2507-Q8æ¨¡å‹æœ€ä½³å‚æ•°ï¼š<BR>
**1ã€OLLAMA_GPU_OVERHEAD ä¸º1GB<BR>**
**2ã€OLLAMA_KV_CACHE_TYPE=q8_0  ï¼›å‡å°KV cacheå ç”¨VRAMï¼ŒåŠ é€ŸPrefillé€Ÿåº¦ï¼ˆå®æµ‹5minTimeoutæ—¶é—´å¤ŸPrefillæœ€å¤§ä¸Šæ–‡å¯ä»¥12-14Kï¼‰<BR>**
**3ã€å¯ç”¨OLLAMA_FLASH_ATTENTIONï¼ˆå¯èƒ½æ˜¯é»˜è®¤ï¼‰<BR>**
4ã€ç¦ç”¨mmap<BR>
**5ã€Optionalï¼šPARAMETER num_ctx 32768**        # 32K ä¸Šä¸‹æ–‡ å’Œ PARAMETER num_predict 20480     # æœ€å¤šä¸€æ¬¡æ€§è¾“å‡º 20K<BR>
6ã€è¿™æ ·åœ¨ç›®æ ‡32Kä¸Šä¸‹æ–‡é—®é¢˜ï¼ˆæœ€å¤§è¾“å‡º20Kçš„ï¼‰,KV cacheä¸è€ƒè™‘flashAttentionï¼ˆå¯èƒ½æ˜¯é»˜è®¤ï¼‰å’Œé»˜è®¤KV=fp16çš„æƒ…å†µä¸‹æœ€å¤§é¢„ç•™æ˜¯3GBï¼ˆéƒ¨åˆ†åœ¨1.9Gåœ¨æ˜¾å­˜1.1Gåœ¨å†…å­˜ï¼Œçº¦ç­‰äºæ¨¡å‹æƒé‡åœ¨VRAMå’ŒRAMä¸Šçš„æ¯”ä¾‹ï¼‰ï¼›**KV=q8_0æ—¶æœ€å¤§é¢„ç•™æ˜¯1.5GBï¼Œ1Gåœ¨æ˜¾å­˜ï¼Œ0.5Gåœ¨å†…å­˜**<BR>
ğŸ”´5ï¼‰**ç°åœ¨æœ¬åœ°è·‘LLMï¼Œæœ€é‡è¦çš„æ˜¯æ˜¾å­˜å¤ŸåŠ è½½å®Œæ•´çš„æƒé‡æ–‡ä»¶+é¢„ç•™KV Cacheï¼ˆ32Kctxé»˜è®¤F16å¯¹äºQwen3-30b-a3b\~3GBï¼‰ï¼›å…¶æ¬¡æ‰æ˜¯GPUï¼Œä¸»æµ4070ç®—åŠ›è¶³å¤Ÿä½†16Gæ˜¾å­˜ä¸å¤Ÿï¼Œæ‰€ä»¥æƒ³ç”¨å¾—å¥½è¿˜è¦ä¸Š24G4090æˆ–32G5090ï¼Œæˆæœ¬ä¾æ—§é«˜ï¼›32G-128Gå¤§å†…å­˜AMD8745ï¼ˆæ ¸æ˜¾780æ¥è¿‘1060ï¼‰/AI-MAX 390ï¼ˆæ ¸æ˜¾æ¥è¿‘4060ï¼‰å¯èƒ½æ˜¯æ€§ä»·æ¯”é«˜ä¸€ç‚¹çš„æ›¿ä»£**<BR>
ğŸ”´6ï¼‰**ç°é˜¶æ®µï¼ˆ2025/10ï¼‰æ¶ˆè´¹çº§GPUæœºå™¨ä¸Šæœ€ä½³é€‰æ‹©ï¼šä»ä¸šåŠ¡ä¸Šè·‘Qwen3-30b-a3b-think-AWQ4æ¨¡å‹ï¼ˆæ™ºåŠ›GPT4.3ï¼Œä¸æ–°ç‰ˆDS V3ç›¸å½“ï¼‰@vLLMï¼ˆæ“…é•¿çº¯GPUï¼‰æœ€åˆé€‚6å¹¶å‘ååé‡èƒ½è¾¾200-300t/sï¼›ç¡¬è¦ä¸ŠQwen3-30b-a3b-Q8çš„è¯åªèƒ½å‹‰å¼ºOllamaä¸€ä¸ªäººç©ä¸”ä¸Šä¸‹æ–‡32KAI-MAX390å¯èƒ½è¾¾åˆ°40t/sï¼Ÿï¼Ÿï¼Ÿæé™æ–¹æ¡ˆå¯èƒ½æ˜¯15Kå…ƒçš„128GAI-MAX390è·‘Qwen3-30b-a3b-FP16ï¼ˆä¸è€ç‰ˆDS R1ç›¸å½“ï¼‰@vLLMå•äººè¾¾åˆ°40t/sï¼Ÿï¼Ÿï¼Ÿ**<BR>
